# Tourist Scheduling System - ADK Multi-Agent Demo

The **Tourist Scheduling System** is a reference implementation of a multi-agent system built with Google's **Agent Development Kit (ADK)**. It demonstrates how autonomous agentsâ€”representing Tourists, Guides, and a Schedulerâ€”can collaborate to solve complex coordination problems in real-time.

This application showcases advanced patterns for building production-ready agentic workflows, including:
*   **Dynamic Service Discovery**: Agents publish their capabilities (A2A Cards) to a central **Agent Directory**, enabling runtime discovery without brittle point-to-point configuration.
*   **Secure Agent-to-Agent (A2A) Communication**: Uses **SLIM (Secure Layer for Intelligent Messaging)** to establish encrypted, authenticated channels between agents.
*   **Observability**: Full integration with **OpenTelemetry** and **Jaeger** to trace requests and tool executions across distributed agent processes.
*   **Human-in-the-Loop**: A real-time **Dashboard** provides visibility into the negotiation and scheduling process.

<img src="docs/tss-demo.gif" alt="TSS Demo" width="800">

## ğŸ“‘ Table of Contents

- [Features](#-features)
- [Integrations](#-integrations)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [Architecture](#-architecture)
- [SLIM Transport](#-slim-transport)
- [Kubernetes Deployment](#-kubernetes-deployment)
- [Distributed Tracing](#-distributed-tracing)
- [Dashboard Features](#-dashboard-features)
- [CLI Reference](#-cli-reference)
- [Development](#-development)
- [License](#-license)

## âœ¨ Features

- **Multi-Agent Coordination**: Scheduler, guides, and tourists working together
- **Dynamic Discovery**: Agents register and discover capabilities via the Agent Directory
- **A2A Communication**: Full A2A compliance with SLIM transport support
- **Real-Time Dashboard**: Live monitoring with WebSocket updates
- **Distributed Tracing**: OpenTelemetry integration with Jaeger visualization
- **LLM-Powered Agents**: Azure OpenAI and Google Gemini integration via LiteLLM

## ğŸ”Œ Integrations

This application leverages several key integrations to provide a robust, production-ready agent ecosystem:

- **[Agent Directory](https://github.com/agntcy/agent-directory)**: A centralized registry where agents publish their A2A Cards (capabilities) and endpoints. This enables dynamic discovery, allowing the Scheduler to find available Guides and Tourists at runtime.
- **[SLIM Transport](https://github.com/agntcy/slim)**: Secure Layer for Intelligent Messaging. Provides encrypted, authenticated communication channels between agents, ensuring data privacy and integrity.
- **[OpenTelemetry](https://opentelemetry.io/) & [Jaeger](https://www.jaegertracing.io/)**: Comprehensive observability stack. Traces requests across agent boundaries, visualizing the full lifecycle of a scheduling task from Tourist request to Guide assignment.
- **LLM Providers**: Flexible integration with **Azure OpenAI** and **Google Gemini** via LiteLLM, powering the intelligent decision-making of the agents.
- **[FastAPI](https://fastapi.tiangolo.com/)**: High-performance web framework used for the Agent Directory and agent HTTP interfaces.

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- [UV](https://github.com/astral-sh/uv) package manager
- Docker (for SLIM transport and tracing)
- Azure OpenAI API key or Google Gemini API key

### Installation

```bash
# Clone the repository
git clone https://github.com/agntcy/agentic-apps.git
cd agentic-apps/tourist_scheduling_system

# Create virtual environment
uv venv
source .venv/bin/activate

# Install dependencies
uv sync

# Configure Azure OpenAI
export AZURE_OPENAI_API_KEY="your-key"
export AZURE_OPENAI_ENDPOINT="https://your-endpoint.openai.azure.com"

# Or Configure Google Gemini
export MODEL_PROVIDER="gemini"
export GOOGLE_GEMINI_API_KEY="your-google-api-key"
# Optional: Specify model (default: gemini/gemini-3-pro-preview)
export MODEL_NAME="gemini/gemini-3-pro-preview"

# Or Configure Ollama (local models)
export MODEL_PROVIDER="ollama"
export OLLAMA_MODEL="llama3.1:8b"
export OLLAMA_HOST="http://localhost:11434"
```

### Docker Builds (Optional)

To build and run the agents as Docker containers:

```bash
# Build all container images
docker compose build

# Start infrastructure and agents
docker compose up -d scheduler ui jaeger
docker compose run --rm guide
docker compose run --rm tourist
```

#### Corporate Proxy / Zscaler Certificate

If you're behind a corporate proxy using Zscaler, you'll need to add the Zscaler root CA certificate for Docker builds to work properly. The Dockerfiles are configured to optionally use this certificate.

1. **Export the Zscaler certificate** using the command line:
   
   **macOS**:
   ```bash
   # From System keychain (most common)
   security find-certificate -c "Zscaler Root CA" -p /Library/Keychains/System.keychain > zscaler-ca.crt
   
   # Or from login keychain
   security find-certificate -c "Zscaler Root CA" -p ~/Library/Keychains/login.keychain-db > zscaler-ca.crt
   ```
   
   **Linux**:
   ```bash
   # Check /etc/ssl/certs/ or ask your IT department
   cp /etc/ssl/certs/zscaler*.pem zscaler-ca.crt
   ```
   
   **Windows** (PowerShell):
   ```powershell
   Get-ChildItem -Path Cert:\LocalMachine\Root | Where-Object {$_.Subject -like "*Zscaler*"} | 
     ForEach-Object { [System.IO.File]::WriteAllText("zscaler-ca.crt", 
       "-----BEGIN CERTIFICATE-----`n" + [Convert]::ToBase64String($_.RawData, 'InsertLineBreaks') + "`n-----END CERTIFICATE-----") }
   ```

2. **The certificate file** should be placed in the `tourist_scheduling_system/` directory:
   ```bash
   tourist_scheduling_system/zscaler-ca.crt
   ```

3. **Rebuild the containers** - they will automatically pick up the certificate:
   ```bash
   docker compose build --no-cache
   ```

> **Note**: The `zscaler-ca.crt` file is in `.gitignore` and will not be committed. If you're not behind Zscaler, the Docker builds will work without it.

### Run the Demo

```bash
# Start infrastructure (SLIM + Jaeger)
./setup.sh start

# Run the demo with SLIM transport
source run.sh --transport slim --tracing
```

**Access Points**:
- Dashboard: http://localhost:10021
- Jaeger UI: http://localhost:16686 (when tracing is enabled)

## ğŸ“ Project Structure

```
tourist_scheduling_system/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/                  # Agent implementations
â”‚   â”‚   â”œâ”€â”€ scheduler_agent.py   # Main scheduler (A2A server, port 10000)
â”‚   â”‚   â”œâ”€â”€ ui_agent.py          # Dashboard web app (A2A server, port 10021)
â”‚   â”‚   â”œâ”€â”€ guide_agent.py       # Tour guide agent (A2A client)
â”‚   â”‚   â”œâ”€â”€ tourist_agent.py     # Tourist agent (A2A client)
â”‚   â”‚   â””â”€â”€ tools.py             # ADK tools (register, match, etc.)
â”‚   â””â”€â”€ core/                    # Core utilities
â”‚       â”œâ”€â”€ a2a_cards.py         # Agent A2A card definitions
â”‚       â”œâ”€â”€ dashboard.py         # Starlette dashboard app
â”‚       â”œâ”€â”€ models.py            # Pydantic data models
â”‚       â”œâ”€â”€ slim_transport.py    # SLIM transport adapter
â”‚       â”œâ”€â”€ tracing.py           # OpenTelemetry setup
â”‚       â”œâ”€â”€ messages.py          # Message types
â”‚       â””â”€â”€ logging_config.py    # Logging configuration
â”œâ”€â”€ scripts/                     # Shell scripts for infrastructure
â”‚   â”œâ”€â”€ spire.sh                 # SPIRE server/agent deployment
â”‚   â”œâ”€â”€ slim-controller.sh       # SLIM controller deployment
â”‚   â”œâ”€â”€ slim-node.sh             # SLIM data plane node deployment
â”‚   â”œâ”€â”€ directory.sh             # Agent Directory deployment
â”‚   â”œâ”€â”€ run_adk_demo.py          # Main demo runner (Python CLI)
â”‚   â”œâ”€â”€ slim-control-csid.yaml.tpl # SPIRE ID template for Controller
â”‚   â”œâ”€â”€ slim-node-csid.yaml.tpl    # SPIRE ID template for Node
â”‚   â””â”€â”€ *-values.yaml            # Helm values files
â”œâ”€â”€ deploy/
â”‚   â””â”€â”€ k8s/                     # Kubernetes manifests
â”‚       â”œâ”€â”€ namespace.yaml       # Namespace and ConfigMap
â”‚       â”œâ”€â”€ scheduler-agent.yaml # Scheduler Deployment
â”‚       â”œâ”€â”€ ui-agent.yaml        # UI Dashboard Deployment
â”‚       â”œâ”€â”€ guide-agent.yaml     # Sample guide agent Jobs
â”‚       â”œâ”€â”€ tourist-agent.yaml   # Sample tourist agent Jobs
â”‚       â”œâ”€â”€ deploy.sh            # Deployment helper script
â”‚       â”œâ”€â”€ spawn-agents.sh      # Scale multiple guides/tourists
â”‚       â”œâ”€â”€ templates/           # Job templates for dynamic generation
â”‚       â””â”€â”€ README.md            # K8s deployment docs
â”œâ”€â”€ setup.sh                     # Local infrastructure management
â”œâ”€â”€ run.sh                       # Demo launcher script (sourceable)
â”œâ”€â”€ slim-config.yaml             # SLIM node configuration
â””â”€â”€ slim-config-otel.yaml        # SLIM config with OpenTelemetry
```

## ğŸ—ï¸ Architecture

### Agent Roles

| Agent | Port | Role |
|-------|------|------|
| Scheduler | 10000 | Central coordinator, matches guides to tourists |
| Dashboard | 10021 | Real-time web UI with WebSocket updates |
| Guides | (via A2A) | LLM-powered tour guides with specializations |
| Tourists | (via A2A) | Visitors requesting specific tour experiences |
| **Directory** | 8888 | Service registry for agent discovery |

### Communication Flow

```
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚   Directory  â”‚
                                   â”‚  (port 8888) â”‚
                                   â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚ Register/Lookup
                                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     A2A/SLIM      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Guide Agent  â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚   Scheduler  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚    Agent     â”‚
                                   â”‚  (port 10000)â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     A2A/SLIM      â”‚              â”‚
â”‚ Tourist Agentâ”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â”‚ HTTP/WS
                                          â–¼
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚  Dashboard   â”‚
                                   â”‚  (port 10021)â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” SLIM Transport

SLIM provides encrypted, high-performance messaging:

```bash
# Start SLIM node
./setup.sh slim start

# Configure SLIM endpoint
export SLIM_ENDPOINT=http://localhost:46357
export SLIM_SHARED_SECRET=supersecretsharedsecret123456789
export SLIM_TLS_INSECURE=true

# Run with SLIM transport
source run.sh --transport slim
```

### SLIM Configuration

See `slim-config.yaml` for node configuration. Key settings:

```yaml
storage:
  type: InMemory
transport:
  type: HTTP
security:
  shared_secret: ${SLIM_SHARED_SECRET}
```

## â˜¸ï¸ Kubernetes Deployment

Deploy the Tourist Scheduling System to Kubernetes with support for both HTTP and SLIM transport modes.

### Prerequisites

- Kubernetes cluster (MicroK8s, GKE, EKS, etc.)
- `kubectl` configured
- `envsubst` (comes with gettext)
- Container images pushed to registry

### Quick Deploy

```bash
cd deploy/k8s

# Set environment
export NAMESPACE=lumuscar-jobs
export IMAGE_REGISTRY=ghcr.io/agntcy/apps
export IMAGE_TAG=latest

# Deploy with HTTP transport (default)
./deploy.sh http

# Or deploy with SLIM transport (requires SLIM infrastructure)
./deploy.sh slim

# Create secrets
kubectl create secret generic azure-openai-credentials \
  --from-literal=api-key=$AZURE_OPENAI_API_KEY \
  --from-literal=endpoint=$AZURE_OPENAI_ENDPOINT \
  --from-literal=deployment-name=${AZURE_OPENAI_DEPLOYMENT_NAME:-gpt-4o} \
  -n $NAMESPACE

# Check status
./deploy.sh status
```

### SLIM Infrastructure Setup

For SLIM transport with mTLS authentication (via SPIRE):

```bash
# Install SPIRE (identity provider)
./scripts/spire.sh install

# Install SLIM controller (with SPIRE enabled)
export SPIRE_ENABLED=true
./scripts/slim-controller.sh install

# Install SLIM node (with SPIRE enabled)
# Default strategy is StatefulSet
export SPIRE_ENABLED=true
./scripts/slim-node.sh install

# Or install SLIM node as DaemonSet
export SLIM_STRATEGY=daemonset
export SPIRE_ENABLED=true
./scripts/slim-node.sh install

# Install Agent Directory (optional)
./scripts/directory.sh install

# Verify
./scripts/spire.sh status
./scripts/slim-controller.sh status
./scripts/slim-node.sh status
```

### Manual Deployment

```bash
# Using envsubst for variable substitution
export NAMESPACE=lumuscar-jobs
export IMAGE_REGISTRY=ghcr.io/agntcy/apps
export IMAGE_TAG=latest
export TRANSPORT_MODE=http  # or slim

# Apply manifests
envsubst < deploy/k8s/namespace.yaml | kubectl apply -f -
envsubst < deploy/k8s/scheduler-agent.yaml | kubectl apply -f -
envsubst < deploy/k8s/ui-agent.yaml | kubectl apply -f -

# Run client agents (Jobs)
envsubst < deploy/k8s/guide-agent.yaml | kubectl apply -f -
envsubst < deploy/k8s/tourist-agent.yaml | kubectl apply -f -
```

### Scaling Multiple Agents

Spawn many guides and tourists with randomized configurations:

```bash
cd deploy/k8s

# Spawn 10 guides and 50 tourists
./spawn-agents.sh guides 10
./spawn-agents.sh tourists 50

# Or spawn both at once
./spawn-agents.sh both 10 50

# Check status
./spawn-agents.sh status

# Clean up
./spawn-agents.sh clean
```

See [deploy/k8s/README.md](deploy/k8s/README.md) for full documentation.

## ğŸ“Š Distributed Tracing

Full OpenTelemetry integration with Jaeger:

```bash
# Start Jaeger
./setup.sh tracing

# Run with tracing
source run.sh --tracing

# View traces
open http://localhost:16686
```

Trace features:
- Request-level spans
- Cross-agent trace propagation
- Tool execution timing
- Error tracking

## ğŸ–¥ï¸ Dashboard Features

The real-time dashboard shows:

- **Guide Pool**: Available guides with specializations and ratings
- **Tourist Queue**: Pending tourist requests with preferences
- **Active Assignments**: Current guide-tourist matches in progress
- **Completed Tours**: Historical data with ratings
- **Communication Log**: Agent message history (guide/tourist/system)

WebSocket provides instant updates as the scheduler processes requests.

## ğŸ“– CLI Reference

### `setup.sh` - Infrastructure Management

```bash
./setup.sh start          # Start SLIM + Jaeger containers
./setup.sh stop           # Stop all containers
./setup.sh clean          # Remove containers and data
./setup.sh slim           # Start only SLIM node
./setup.sh tracing        # Start only Jaeger
./setup.sh status         # Show container status
```

### `run.sh` - Demo Launcher

The script can be **sourced** to preserve environment variables or run directly:

```bash
# Source to inherit current shell's env vars (recommended)
source run.sh [options]

# Or run directly
./run.sh [options]

# Options
--transport MODE          # http (default) or slim
--provider NAME           # Model provider: azure (default) or google
--tracing                 # Enable OpenTelemetry tracing
--scheduler-port N        # Scheduler port (default: 10000)
--ui-port N               # Dashboard port (default: 10021)
--guides N                # Number of guides (default: 2)
--tourists N              # Number of tourists (default: 3)
--duration N              # Duration in minutes (0=single run)
--interval N              # Delay between requests (default: 1.
--real-agents             # Use real ADK guide/tourist agents instead of simulation0s)
--no-demo                 # Start servers only, no demo traffic

# Control
./run.sh stop             # Stop all agents
./run.sh clean            # Stop agents and clean up
```

### `scripts/run_adk_demo.py` - Python Demo Runner

For direct Python control:

```bash
# Interactive console demo
.venv/bin/python scripts/run_adk_demo.py --mode console

# Full multi-agent demo (spawns all processes)
.venv/bin/python scripts/run_adk_demo.py --mode multi

# Simulation only (requires agents already running)
.venv/bin/python scripts/run_adk_demo.py --mode sim --port 10000 --ui-port 10021

# With SLIM transport
.venv/bin/python scripts/run_adk_demo.py --mode multi --transport slim

# Options
--mode MODE               # console, server, multi, or sim
--port N                  # Scheduler port (default: 10000)
--ui-port N               # Dashboard port (default: 10021)
--guides N                # Number of guides (default: 2)
--tourists N              # Number of tourists (default: 3)
--transport MODE          # http or slim
--slim-endpoint URL       # SLIM node URL
--tracing/--no-tracing    # Enable OpenTelemetry
--duration N              # Duration in minutes (0=single run)
--interval N              # Delay between requests
--fast/--no-fast          # Skip LLM calls for testing
```

### Environment Variables

```bash
# Required (Choose one provider)
export AZURE_OPENAI_API_KEY="your-key"
# OR
export GOOGLE_GEMINI_API_KEY="your-google-api-key"

# Optional
export MODEL_PROVIDER="openai"                 # or "gemini"
export MODEL_NAME="gemini/gemini-3-pro-preview" # for Gemini
export AZURE_OPENAI_ENDPOINT="https://..."
export TRANSPORT=slim                          # Default transport
export SLIM_ENDPOINT=http://localhost:46357    # SLIM node URL
export SLIM_SHARED_SECRET=your-secret          # SLIM auth secret
export SCHED_PORT=10000                        # Scheduler port
export UI_PORT=10021                           # Dashboard port
export DIR_PORT=8888                           # Agent Directory port
export DIRECTORY_CLIENT_SERVER_ADDRESS=localhost:8888 # Directory address
```

## ğŸ§ª Development

### Running Tests

uv sync
./setup.sh install        # Ensure dependencies
uv run pytest tests/
```

### Adding New Agents

1. Create agent in `src/agents/`
2. Define A2A card in `src/core/a2a_cards.py`
3. Add tools in `src/agents/tools.py`
4. Update `run_adk_demo.py` to spawn agent

### Logs

Logs are written to `logs/` directory:
- `scheduler_agent.log`
- `ui_agent.log`
- OpenTelemetry trace files (`.json`)

## ğŸ“„ License

Apache 2.0 - See [LICENSE](../LICENSE)
