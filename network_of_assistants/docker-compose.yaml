services:

  noa-slim:
    image: ghcr.io/agntcy/slim:0.3.15
    networks:
      - app_network
    ports:
    - "46357:46357"
    volumes:
      - ./noa-slim/slim-config.yaml:/config.yaml
    command: ["/slim", "--config", "/config.yaml"]

  noa-moderator:
    build:
      context: .
      dockerfile: noa-moderator/Dockerfile
    networks:
      - app_network
    depends_on:
      - noa-slim
      - otel-collector
    volumes:
      - ./dir:/app/ads
    environment:
      - MODERATOR_LLM_TYPE=ollama
      - MODERATOR_LLM_MODEL=llama3.1:8b
      - MODERATOR_LLM_BASE_URL=http://host.docker.internal:11434
      - SLIM_ENDPOINT=http://noa-slim:46357
      - AGENTS_DIR=/app/ads/datamodels
      - WITH_OBS=True
      - OTLP_HTTP_ENDPOINT=http://otel-collector:4318

  noa-file-assistant:
    build:
      context: .
      dockerfile: noa-file-assistant/Dockerfile
    networks:
      - app_network
    depends_on:
      - noa-slim
      - noa-moderator
      - otel-collector
    volumes:
      - ./noa-file-assistant/files:/home/files
    environment:
      - ASSISTANT_LLM_TYPE=ollama
      - ASSISTANT_LLM_MODEL=llama3.1:8b
      - ASSISTANT_LLM_BASE_URL=http://host.docker.internal:11434
      # RAG embeddings still need OpenAI-compatible API (or use Ollama embeddings)
      - ASSISTANT_RAG_TYPE=ollama
      - ASSISTANT_RAG_MODEL=nomic-embed-text
      - ASSISTANT_RAG_BASE_URL=http://host.docker.internal:11434
      - SLIM_ENDPOINT=http://noa-slim:46357
      - ASSISTANT_ID=noa-file-assistant
      - ASSISTANT_DOC_DIR=/home/files
      - FILE_URL=https://arxiv.org/pdf/2410.10934?
      - WITH_OBS=True
      - OTLP_HTTP_ENDPOINT=http://otel-collector:4318
      # SSL cert paths for Python requests behind corporate proxy
      - REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt
      - SSL_CERT_FILE=/etc/ssl/certs/ca-certificates.crt

  noa-web-surfer:
    build:
      context: .
      dockerfile: noa-web-surfer/Dockerfile
    networks:
      - app_network
    depends_on:
      - noa-slim
      - noa-moderator
      - otel-collector
    environment:
      # Note: MultimodalWebSurfer requires vision capabilities - llava model recommended
      - WEB_SURFER_LLM_TYPE=ollama
      - WEB_SURFER_LLM_MODEL=llava:7b
      - WEB_SURFER_LLM_BASE_URL=http://host.docker.internal:11434
      - SLIM_ENDPOINT=http://noa-slim:46357
      - WEB_SURFER_ID=noa-web-surfer-assistant
      - WITH_OBS=True
      - OTLP_HTTP_ENDPOINT=http://otel-collector:4318

  noa-math-assistant:
    build:
      context: .
      dockerfile: noa-math-assistant/Dockerfile
    networks:
      - app_network
    depends_on:
      - noa-slim
      - noa-moderator
      - otel-collector
    environment:
      - MATH_ASSISTANT_LLM_TYPE=ollama
      - MATH_ASSISTANT_LLM_MODEL=llama3.1:8b
      - MATH_ASSISTANT_LLM_BASE_URL=http://host.docker.internal:11434
      - SLIM_ENDPOINT=http://noa-slim:46357
      - MATH_ASSISTANT_ID=noa-math-assistant
      - WITH_OBS=True
      - OTLP_HTTP_ENDPOINT=http://otel-collector:4318

  noa-user-proxy:
    build:
      context: .
      dockerfile: noa-user-proxy/Dockerfile
    networks:
      - app_network
    ports:
      - "8000:8000"
    environment:
      - SLIM_ENDPOINT=http://noa-slim:46357
    stdin_open: true
    tty: true
    depends_on:
      - noa-slim
      - noa-moderator
      - noa-file-assistant
      - noa-web-surfer
      - noa-math-assistant

  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: noa-otel-collector
    networks:
      - app_network
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    volumes:
      - ./otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml
    command: ["--config", "/etc/otelcol-contrib/config.yaml"]
    depends_on:
      - jaeger

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: noa-jaeger
    networks:
      - app_network
    ports:
      - "16686:16686"  # Jaeger UI
      - "14250:14250"  # gRPC for OTEL
    environment:
      - COLLECTOR_OTLP_ENABLED=true

networks:
  app_network:
    driver: bridge
